[{"page": 1, "quote": "\u00c7i\u00e7ek et al. [1] proposed the 3D U-Net to extend the classical model on semantic segmentation of images to three dimensions."}, {"page": 1, "quote": "The good performance of nnU-Net makes it a common baseline for medical image segmentation tasks."}, {"page": 1, "quote": "This paper provides a novel 3D medical image segmentation model structure called nnY-Net."}, {"page": 2, "quote": "We use Swin Transformer as the encoder and Conv-NeXt as the decoder to innovatively design a new network structure called Swin-NeXt."}, {"page": 2, "quote": "Fig. 4 graphically illustrates W-MSA and SW-MSA operations for 3D images."}, {"page": 3, "quote": "After comprehensive experiments, we find that the third solution using Cross Attention fusion ensures stable improvement."}, {"page": 3, "quote": "The performance measures include Dice, HD95, MIoU, accuracy, recall, and precision."}, {"page": 3, "quote": "We then concatenate the encoding tensor and fusion tensor."}, {"page": 5, "quote": "We can see that the fusion method using Cross Attention performs the best."}, {"page": 6, "quote": "the convolution-based Conv-NeXt module has the strongest ability to decode at the pixel level, and the cross-attention modal fusion has the best results."}]