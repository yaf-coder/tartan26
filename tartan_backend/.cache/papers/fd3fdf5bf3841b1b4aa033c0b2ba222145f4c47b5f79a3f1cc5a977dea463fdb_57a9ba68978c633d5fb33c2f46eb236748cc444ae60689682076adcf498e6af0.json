[{"page": 1, "quote": "The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks, resulting in a possibly simpler optimization problem for the optimizer."}, {"page": 1, "quote": "Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively."}, {"page": 1, "quote": "We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks."}, {"page": 2, "quote": "The underlying hypothesis behind our architecture is that the model can more e\ufb00ectively capture \ufb01ne-grained details of the foreground objects when high-resolution feature maps from the encoder network are gradually enriched prior to fusion with the corresponding semantically rich feature maps from the decoder network."}, {"page": 4, "quote": "The hypothesis is that the optimizer would face an easier optimization problem when the received encoder feature maps and the corresponding decoder feature maps are semantically similar."}, {"page": 4, "quote": "UNet++ generates full resolution feature maps at multiple semantic levels, {x0,j, j\u2208{ 1, 2, 3, 4}}, which are amenable to deep supervision."}, {"page": 6, "quote": "All convolutional layers along a skip pathway (Xi,j) use k kernels of size 3\u00d73 (or 3\u00d73\u00d73 for 3D lung nodule segmentation) where k = 32\u00d7 2i."}, {"page": 8, "quote": "We evaluated UNet++ using four medical imaging datasets covering lung nodule segmentation, colon polyp segmentation, cell nuclei segmentation, and liver segmentation."}, {"page": 8, "quote": "Our experiments demonstrated that UNet++ with deep supervision achieved an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively."}, {"page": 8, "quote": "Deep supervision also enables more accurate segmentation particularly for lesions that appear at multiple scales such as polyps in colonoscopy videos."}]