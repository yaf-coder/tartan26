[{"page": 1, "quote": "The nnU-Net [2] further improves upon U-Net and integrates automated pre-processing and post-processing techniques with parameter selection guidelines [2]."}, {"page": 1, "quote": "Using a Transformer structure, UNETR utilizes ViT as an encoder and retains the convolutional layer of U-Net as a decoder [3]."}, {"page": 1, "quote": "\u00c7i\u00e7ek et al. [1] proposed the 3D U-Net to extend the classical model on semantic segmentation of images to three dimensions."}, {"page": 2, "quote": "We use Swin Transformer as the encoder and Conv-NeXt as the decoder to innovatively design a new network structure called Swin-NeXt."}, {"page": 3, "quote": "To include the information of tabular data for model training, we consider fusing the features of 3D images and tabular data in the last layer of the encoder, the Bottleneck layer."}, {"page": 3, "quote": "The third one is through Cross Attention mechanism, where the feature map is used as Key and Value, and the vector features are used as Query to calculate the attention weights."}, {"page": 6, "quote": "We integrated our proposed Swin-NeXt with Cross-Attention framework into this framework, which makes the model converge faster."}, {"page": 6, "quote": "the cross-attention modal fusion has the best results."}]