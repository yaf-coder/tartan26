[{"page": 1, "quote": "Recent Advances of Continual Learning in Computer Vision: An Overview"}, {"page": 2, "quote": "We summarize the main contributions of this overview as follows. (1) A systematic review of the recent progress of continual learning in computer vision is provided."}, {"page": 2, "quote": "In recent years, an increasing number of continual learning methods have been proposed in various subareas of computer vision."}, {"page": 3, "quote": "Recently, a large number of continual learning methods have been proposed for various computer vision tasks, such as image classification, object detection, semantic segmentation, and image generation."}, {"page": 4, "quote": "EWC injects a new quadratic penalty term into the loss function to restrict the model from modifying the weights that are important for the previously learned tasks."}, {"page": 5, "quote": "Volpi et al. [47] further proposed a meta-learning strategy to consecutively learn from different visual domains."}, {"page": 5, "quote": "Ren et al. [40] focused on incremental few-shot learning."}, {"page": 6, "quote": "Zeng et al. [52] proposed an Orthogonal Weights Modification algorithm."}, {"page": 7, "quote": "Douillard et al. [78] handled the background semantic distribution shift problem by generating pseudo-labels of the background from the previously learned model."}, {"page": 7, "quote": "Moreover, Douillard et al. [67] regarded continual learning as representation learning and proposed a distillation loss called Pooled Outputs Distillation."}, {"page": 8, "quote": "Wu et al. [92] adapted the knowledge distillation method for class-conditioned image generation."}, {"page": 9, "quote": "In image classification, Liu et al. [99] proposed a method named Indirect Discriminant Alignment (IDA)."}, {"page": 11, "quote": "Tao et al. [142] proposed to store the topology of the feature space of the previous tasks through a neural gas network [143] and proposed the TOpology-Preserving knowledge InCrementer framework to preserve the neural gas topology of the previous tasks and adapt to new tasks given a few data instances."}, {"page": 11, "quote": "Ye and Bors [132] further explored continual learning in image generation, and they proposed a new memory management method DCM that can be used in both supervised and unsupervised continual learning scenarios."}, {"page": 12, "quote": "Zhu et al. [149] proposed to store a class-representative prototype for each previous task and augment these prototypes to preserve the decision boundaries of the previous tasks."}]