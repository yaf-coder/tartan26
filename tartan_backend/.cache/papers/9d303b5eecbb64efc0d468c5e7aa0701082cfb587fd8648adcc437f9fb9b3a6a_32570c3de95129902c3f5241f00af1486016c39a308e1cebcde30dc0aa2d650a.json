[{"page": 1, "quote": "We test KBNet on public depth completion benchmarks, where it outperforms the state of the art by 30% indoor and 8% outdoor when the same camera is used for training and testing."}, {"page": 1, "quote": "We propose a deep neural network architecture to infer dense depth from an image and a sparse point cloud."}, {"page": 2, "quote": "Our proposed architecture only uses 6.9M parameters and our choice of supervision allows us to continuously learn even after the system is deployed."}, {"page": 2, "quote": "Unlike [43], our method does not require ground truth and is not limited to a specific domain."}, {"page": 3, "quote": "Our contributions include (a) a sparse-to-dense module that learns a dense representation of the sparse point cloud, (b) an unsupervised depth completion method that takes calibration information as input to the model."}, {"page": 3, "quote": "Our network is very light-weight and fast, yet achieves the state of the art."}, {"page": 6, "quote": "Overall, we beat the best performing method [39] by an average of 8% and up to 10.4% on the iMAE metric with a 11.5% reduction in model size."}, {"page": 6, "quote": "Our method outperforms all unsupervised methods across all metrics on the KITTI leaderboard."}, {"page": 8, "quote": "By optimizing for the trade-off between density and detail, our S2D module learns to exploit the natural statistics of the dataset to obtain a dense representation more compatible with the scene."}, {"page": 10, "quote": "Alex Wong, Xiaohan Fei, Byung-Woo Hong, and Stefano Soatto. An adaptive framework for learning unsupervised depth completion."}, {"page": 10, "quote": "Alex Wong, Xiaohan Fei, Stephanie Tsuei, and Stefano Soatto. Unsupervised depth completion from visual inertial odometry."}]