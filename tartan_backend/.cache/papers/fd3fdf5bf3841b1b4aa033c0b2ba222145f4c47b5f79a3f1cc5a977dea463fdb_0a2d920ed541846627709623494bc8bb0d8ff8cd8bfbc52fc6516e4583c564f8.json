[{"page": 1, "quote": "We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar."}, {"page": 1, "quote": "Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively."}, {"page": 1, "quote": "We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks."}, {"page": 1, "quote": "The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks."}, {"page": 2, "quote": "To address the need for more accurate segmentation in medical images, we present UNet++, a new segmentation architecture based on nested and dense skip connections."}, {"page": 6, "quote": "UNet++ generates four segmentation maps given an input image, which will be further averaged to generate the \ufb01nal segmentation map."}, {"page": 8, "quote": "We evaluated UNet++ using four medical imaging datasets covering lung nodule segmentation, colon polyp segmentation, cell nuclei segmentation, and liver segmentation."}, {"page": 8, "quote": "Our experiments demonstrated that UNet++ with deep supervision achieved an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively."}, {"page": 8, "quote": "Deep supervision also enables more accurate segmentation particularly for lesions that appear at multiple scales such as polyps in colonoscopy videos."}]