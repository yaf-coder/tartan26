[{"page": 1, "quote": "the main goal being to reconstruct the true generative factors of data."}, {"page": 2, "quote": "we formally define concepts as affine subspaces of some underlying representation space."}, {"page": 7, "quote": "The core idea is to utilize contrastive learning as follows."}, {"page": 8, "quote": "we build a neural architecture for this classification problem with the final layer mimicking the log-odds expression above."}, {"page": 9, "quote": "ITI is an activation patching technique that controls the behavior of LLMs during inference time, in particular it promotes truthfulness."}, {"page": 10, "quote": "We proposed a formal definition of concepts and studied under what conditions they can be provably recovered, suggesting what representations foundation models learn."}, {"page": 11, "quote": "Machine learning interpretability: A survey on methods and metrics."}, {"page": 12, "quote": "Independent component analysis: algorithms and applications."}, {"page": 12, "quote": "Deep learning."}, {"page": 14, "quote": "Learning to generate reviews and discovering sentiment."}, {"page": 14, "quote": "Toward causal representation learning."}, {"page": 14, "quote": "From statistical to causal learning."}, {"page": 16, "quote": "Representation engineering: A top-down approach to ai transparency."}, {"page": 16, "quote": "Contrastive learning inverts the data generating process."}, {"page": 16, "quote": "A top-down approach to ai transparency."}]