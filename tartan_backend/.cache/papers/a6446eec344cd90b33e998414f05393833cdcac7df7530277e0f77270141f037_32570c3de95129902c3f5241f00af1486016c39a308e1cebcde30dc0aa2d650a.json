[{"page": 1, "quote": "To compare our method to prior work, we adopt the unsupervised KITTI depth completion benchmark, where we achieve state-of-the-art performance."}, {"page": 3, "quote": "our VGG11 model outperforms both [1] and [3]."}, {"page": 4, "quote": "We show the effectiveness of this approach by achieving the state-of-the-art on the unsupervised KITTI depth completion benchmark with half as many parameters as the prior-art."}, {"page": 5, "quote": "Although inertials are not directly present in the loss, their role in metric depth completion is crucial."}, {"page": 6, "quote": "Our VGG11 model outperforms the state-of-the-art [3] on every metric by as much as 12.8% while using 48.4% fewer parameters."}, {"page": 6, "quote": "Our light-weight VGG8 model also outperforms [3] on MAE, RMSE, and iMAE while [3] beat our VGG8 by 2.2% on iRMSE."}, {"page": 7, "quote": "Yet, our method is still able to produce reasonable results for indoor scenes with a MAE of\u2248 8.5 cm on 0.5% density and \u2248 17.9 cm when given only 0.05%."}, {"page": 8, "quote": "We compare the variants of our pose network."}, {"page": 9, "quote": "To give some \ufb02avor of the VOID dataset, Fig. 9 shows a set of images (top inset) sampled from video sequences in VOID, and output of our visual-inertial odometry (VIO) system."}, {"page": 9, "quote": "In the main paper, we introduced the \u201cVisual Odometry with Inertial and Depth\u201d (VOID) dataset with which we propose a new depth completion benchmark."}, {"page": 10, "quote": "Our approach can provide detailed reconstructions of scenes from both indoor (e.g. right panel, last row: equipment from mechanical lab) and outdoor settings."}, {"page": 11, "quote": "We perform an ablation study on our pose representation by jointly training our depth completion network and pose network on KITTI depth completion dataset."}]